{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>tweet</th>\n",
       "      <th>countnoun</th>\n",
       "      <th>countverb</th>\n",
       "      <th>countadj</th>\n",
       "      <th>countadp</th>\n",
       "      <th>countadv</th>\n",
       "      <th>countnum</th>\n",
       "      <th>countaux</th>\n",
       "      <th>countconj</th>\n",
       "      <th>countdet</th>\n",
       "      <th>countintj</th>\n",
       "      <th>countpart</th>\n",
       "      <th>countpron</th>\n",
       "      <th>countpropn</th>\n",
       "      <th>countpunct</th>\n",
       "      <th>countsconj</th>\n",
       "      <th>countx</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>sabsebadajhootamodi is an apt way to describe...</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>narendramodi sureshpprabhu harvotemodiko</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>deshkishaanmodi</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>ajaydevgn narendramodi ravikishann nirahua ma...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>well in my 1 honourable narendramodi looks tre...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   i                                              tweet  countnoun  countverb  \\\n",
       "0  2   sabsebadajhootamodi is an apt way to describe...          7          6   \n",
       "1  3          narendramodi sureshpprabhu harvotemodiko           3          0   \n",
       "2  4                                   deshkishaanmodi           0          1   \n",
       "3  5   ajaydevgn narendramodi ravikishann nirahua ma...          3          1   \n",
       "4  6  well in my 1 honourable narendramodi looks tre...          4          1   \n",
       "\n",
       "   countadj  countadp  countadv  countnum  countaux  countconj  countdet  \\\n",
       "0         2         1         0         0         0          0         3   \n",
       "1         0         0         0         0         0          0         0   \n",
       "2         0         0         0         0         0          0         0   \n",
       "3         2         0         0         0         0          0         0   \n",
       "4         4         2         2         0         0          0         1   \n",
       "\n",
       "   countintj  countpart  countpron  countpropn  countpunct  countsconj  \\\n",
       "0          0          1          1           0           0           0   \n",
       "1          0          0          0           0           0           0   \n",
       "2          0          0          0           0           0           0   \n",
       "3          0          0          0           0           0           0   \n",
       "4          0          0          0           0           0           0   \n",
       "\n",
       "   countx  sentiment_score  target  \n",
       "0       0             0.60       1  \n",
       "1       0             0.00       1  \n",
       "2       0             0.00       1  \n",
       "3       0             0.00       2  \n",
       "4       0            -0.55       2  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read in the data\n",
    "#df = pd.read_csv('test_classifier_Input_for_classifier_stable.csv')\n",
    "df = pd.read_csv('test_classifier_Input_for_classifier_new_stable.csv')\n",
    "df.columns=['i','tweet','countnoun','countverb','countadj','countadp','countadv','countnum','countaux','countconj','countdet','countintj','countpart','countpron','countpropn','countpunct','countsconj','countx','sentiment_score','target']  \n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Sample the data to speed up computation\n",
    "# Comment out this line to match with lecture\n",
    "#df = df.sample(frac=0.1, random_state=10)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_names_df = ['i','tweet','countnoun','countverb','countadj','countadp','countadv','countnum','countaux','countconj','countdet','countintj','countpart','countpron','countpropn','countpunct','countsconj','countx','sentiment_score']\n",
    "#x_df = df[feature_names_df]\n",
    "#print (x_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_df = df['target']\n",
    "#print (y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and test sets\n",
    "'''X_train, X_test, y_train, y_test = train_test_split(x_df, \n",
    "                                                    y_df, \n",
    "                                                    random_state=0)'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['tweet'], \n",
    "                                                    df['target'], \n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33                     narendramodi follow jahnavijain_ \n",
      "171    continuamos con los mods modificados aun no se...\n",
      "76     he is known for his bravery and courage during...\n",
      "168    many bjp fans claim modi has boosted indias in...\n",
      "222                                      apnamodiaayega \n",
      "                             ...                        \n",
      "67                               datadarbar lahoreblast \n",
      "192     narendramodi pooja aryan_rns ashutos smritiir...\n",
      "117    hoy en el hospital un de los pacientes atend e...\n",
      "47                         rabridevirjd modiaanewalahai \n",
      "172                              got feat narendra modi \n",
      "Name: tweet, Length: 185, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print (X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33     2\n",
      "171    3\n",
      "76     3\n",
      "168    2\n",
      "222    2\n",
      "      ..\n",
      "67     3\n",
      "192    1\n",
      "117    3\n",
      "47     1\n",
      "172    2\n",
      "Name: target, Length: 185, dtype: int64\n",
      "185\n"
     ]
    }
   ],
   "source": [
    "print (y_train)\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train first entry:\n",
      "\n",
      "  narendramodi follow jahnavijain_ \n",
      "\n",
      "\n",
      "X_train shape:  (185,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train first entry:\\n\\n', X_train.iloc[0])\n",
    "print('\\n\\nX_train shape: ', X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Fit the CountVectorizer to the training data\n",
    "vect = CountVectorizer().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2s', '__', 'aadhar', 'aajtak', 'aane', 'aap', 'aayega', 'aayegatohmodihi', 'aayegatomodihi', 'abhoganyay', 'abkibaarkiskisarkar', 'abkibaarpaar', 'ably', 'about', 'above', 'abpnewstv', 'absent', 'abt', 'accept', 'acche', 'acchi', 'acciones', 'account', 'accountability', 'accused', 'achievement', 'across', 'acting', 'actually', 'added', 'address', 'addressing', 'admiral', 'adoption', 'advani', 'afraid', 'after', 'again', 'against', 'agar', 'air', 'aise', 'ajaydevgn', 'ajaykushwaha_', 'ajaypandey__', 'ak', 'akbar', 'akshay', 'al', 'all', 'allah', 'alleged', 'allow', 'allowed', 'also', 'altnews', 'always', 'am', 'ambedkars', 'amit', 'amitbehere', 'amitshah', 'amitshahoffice', 'amp', 'amrica', 'amritabhinder', 'an', 'and', 'ani', 'anil_baluni', 'animali', 'anirbanganguly', 'annualised', 'annually', 'annuler', 'another', 'answer', 'anujg', 'anupamkpandey', 'anuraag_saxena', 'any', 'anything', 'anyway', 'aoc', 'aperta', 'apnamodiaayega', 'apne', 'apologetic', 'app', 'appointed', 'apt', 'aragorn', 'are', 'armed', 'arms', 'arriva', 'artwork', 'aryan_rns', 'as', 'ashutos', 'ask', 'asked', 'asks', 'assassin', 'asses', 'at', 'atend', 'atmosphere', 'attack', 'attacked', 'attempt', 'atuendo', 'audited', 'aun', 'aur', 'aura', 'aux', 'average', 'avidya', 'avoir', 'awake', 'awas', 'awkward', 'axes', 'aybps', 'ayegatohmodihi', 'babua', 'back', 'backs', 'bags', 'bahut', 'bait', 'baja', 'banega', 'banerjee', 'bank', 'bankruptcy', 'barad', 'barrios', 'based', 'bata', 'bay', 'bbc', 'be', 'beaten', 'beautifully', 'beautyfromitaly', 'because', 'been', 'behaviour', 'being', 'believes', 'benefit', 'benefited', 'bengal', 'bengalwithbjp', 'best', 'beta', 'betrayal', 'better', 'bhag', 'bhagaya', 'bhakts', 'bhanu', 'bharat', 'bharatkagarvhemodi', 'bharatkagarvmodi', 'bharatmangemodidobara', 'bhola__', 'bhopal', 'bhrashtachari', 'bigoted', 'bikram', 'billion', 'bills', 'bjp', 'bjp___', 'bjpgujarat', 'bjpindia', 'bjpkarnataka', 'bjpmp', 'bjppunjab', 'bjps', 'black', 'blackmail', 'bless', 'blessing', 'bloomberg', 'blot', 'blunder', 'bmeteo', 'bold', 'bolivianos', 'boosted', 'borivali', 'bottomline', 'boy', 'boycottamazon', 'brave', 'bravery', 'breaking', 'bridged', 'british', 'bro', 'brother', 'brought', 'bsp', 'btvi', 'bua', 'builders', 'building', 'built', 'bulldoze', 'bulles', 'buongiorno', 'buses', 'business', 'but', 'buy', 'by', 'byebyemodi', 'cag', 'call', 'called', 'calls', 'calories', 'came', 'campaign', 'campaigning', 'can', 'canadian', 'candidate', 'candidates', 'cannot', 'capitalisation', 'capitalists', 'care', 'carisimas', 'cars', 'case', 'caste', 'ce', 'celebrations', 'center', 'central', 'ceo_uidai', 'cest', 'chairman', 'chal', 'chang', 'chanted', 'chanting', 'charges', 'chauvinist', 'cheated', 'cheez', 'chehre', 'chiediamo', 'child', 'childhood', 'children', 'chit', 'chose', 'chosen', 'chouhanshivraj', 'christian', 'cierto', 'city', 'claim', 'claimed', 'claims', 'clarified', 'class', 'cleaneating', 'click', 'clinimcally', 'clives', 'clocks', 'cmohry', 'coalition', 'code', 'codice', 'colleague', 'collecting', 'color', 'come', 'comes', 'command', 'comment', 'commodifying', 'commodities', 'commodity', 'common', 'communal', 'community', 'como', 'companies', 'composed', 'con', 'concluding', 'conference', 'congi', 'congratulations', 'congress', 'congressi', 'congressneveragain', 'connected', 'considers', 'consolidate', 'construction', 'continuamos', 'continued', 'continuous', 'cop', 'copper', 'corrupt', 'corruption', 'cosas', 'cost', 'could', 'couldve', 'country', 'courage', 'cpm', 'crazy', 'credit', 'crisis', 'crony', 'crook', 'crore', 'crowd', 'cruise', 'cualquier', 'cuando', 'cuenta', 'culturally', 'cvoter', 'daily', 'darpok', 'darta', 'dases', 'datadarbar', 'day', 'dbt', 'de', 'deal', 'dear', 'death', 'decades', 'deceitfulness', 'deception', 'decisions', 'declare', 'declines', 'deendayal', 'defeat', 'defence', 'defines', 'deformar', 'del', 'delhi', 'deliverance', 'delivered', 'delivery', 'della', 'democracy', 'demolished', 'demonetisation', 'depressing', 'describe', 'deshbakht', 'deshkagauravmodi', 'deshkedilmeimodi', 'deshkipasandmodi', 'deshkishaanmodi', 'desirable', 'despicable', 'destroying', 'details', 'dev_fadnavis', 'developed', 'development', 'devilji_', 'dhanbad', 'dhpoliticaltheatre', 'dhumes', 'di', 'dial', 'diamond', 'dictionary', 'did', 'didi', 'didis', 'didn', 'didnt', 'diegodelorenzis', 'different', 'digvijaya', 'dikhaunga', 'din', 'dirt', 'disastrous', 'discourse', 'disgusting', 'dissected', 'distract', 'divisions', 'divyan', 'diya', 'dna', 'do', 'does', 'doesn', 'doing', 'don', 'done', 'dont', 'donthi', 'door', 'dopo', 'down', 'downgrading', 'dr', 'dream', 'drive', 'drogas', 'du', 'dua', 'duomodimilano', 'durga', 'during', 'each', 'eagerly', 'earlier', 'ease', 'easing', 'eatwell', 'ecisveep', 'economic', 'economy', 'editorials', 'ek', 'ek_proud_indian', 'el', 'elder', 'elect', 'elections', 'else', 'email', 'emendamento', 'eminent', 'empower', 'empowering', 'en', 'end', 'endgame', 'endorsed', 'enfermedades', 'english', 'enough', 'enrich', 'entire', 'era', 'eran', 'es', 'esta', 'estas', 'esto', 'estudios', 'estuvo', 'et', 'etc', 'even', 'ever', 'every', 'everyday', 'everyone', 'everything', 'evm', 'example', 'exclusive', 'exercise', 'exist', 'expanding', 'expecting', 'expense', 'experiencing', 'exports', 'exposes', 'expression', 'exsecular', 'extradition', 'extreme', 'face', 'facilitated', 'facilities', 'fact', 'factored', 'fait', 'families', 'family', 'fans', 'far', 'fast', 'father', 'favour', 'fayedsouza', 'feat', 'feedback', 'feel', 'fekoslovakian', 'feminists', 'fer', 'fermare', 'few', 'fictitious', 'fighting', 'fill', 'filled', 'fin', 'fir', 'first', 'focusing', 'foire', 'follow', 'followed', 'for', 'forces', 'forgotten', 'form', 'former', 'found', 'fourteen', 'free', 'freedom', 'fridayfeeling', 'fridaymotivation', 'fridaythoughts', 'friend', 'friends', 'from', 'fuelled', 'fulfilled', 'fun', 'fund', 'fundamentalist', 'fundamentalists', 'fy', 'gandhi', 'gandhis', 'gathbandhan', 'gauravbjpindia', 'gaya', 'gdbakshije', 'gdp', 'gentle', 'get', 'girl', 'giv', 'give', 'gives', 'giving', 'gl', 'go', 'godse', 'goes', 'going', 'gone', 'good', 'got', 'government', 'govt', 'govts', 'great', 'greatly', 'grew', 'group', 'growth', 'grudge', 'guess', 'gurcharan', 'guys', 'habitual', 'hablar', 'hacer', 'hackearon', 'had', 'hai', 'hailed', 'half', 'hallelujah', 'hand', 'happen', 'harbour', 'hard', 'hardilmeimodi', 'hargharmodikesaath', 'harvotemodiko', 'haryana', 'has', 'hasn', 'hate', 'hates', 'hatred', 'have', 'having', 'he', 'headquarters', 'healthyliving', 'hear', 'heart', 'heckled', 'heights', 'held', 'helples', 'hemodilisis', 'hence', 'hentai___queen', 'hentai_aoi_hime', 'hentaiidxd', 'her', 'here', 'hero', 'hey', 'hi', 'high', 'him', 'hindus', 'hindustan', 'his', 'ho', 'holi', 'home', 'honge', 'honourable', 'hook', 'hope', 'hospital', 'hours', 'household', 'houses', 'how', 'hoy', 'hte', 'huge', 'hui', 'hurt', 'hyped', 'hypocrisy', 'iaf', 'ianuragthakur', 'ideology', 'if', 'iftar', 'igay', 'ignorance', 'ignore', 'image', 'imagine', 'imgrasshopper', 'imminent', 'important', 'in', 'incindia', 'incindialive', 'incluso', 'indeed', 'india', 'indian', 'indians', 'indias', 'indiatoday', 'indicating', 'indices', 'indira', 'infamous', 'inmunosupresoras', 'ins', 'inside', 'inspired', 'insulting', 'integrator', 'international', 'internet', 'interview', 'into', 'inventing', 'inverview', 'iphone', 'iran', 'irritated', 'is', 'ise', 'ishashishekhar', 'island', 'issue', 'issues', 'it', 'its', 'jahnavijain_', 'jai', 'jaihind', 'jains', 'jannonce', 'jayantsinha', 'jayapradamp', 'jayega', 'jayprakash', 'jeetegatomodihi', 'jharkhandbolemodimodi', 'ji', 'jihad', 'jihadi', 'jija', 'job', 'jobs', 'jokes', 'jonathan', 'joota', 'jouer', 'journalism', 'journalist', 'journalists', 'journey', 'judiciary', 'jueves', 'juganu', 'juice_', 'just', 'juste', 'justiceforvishnugoswami', 'kaafi', 'kab', 'kafur', 'kanwal', 'kashi', 'kattar', 'ke', 'keep', 'keeping', 'kehte', 'khanumarfa', 'kharge', 'khud', 'ki', 'kill', 'killed', 'killings', 'kind', 'kinda', 'km', 'know', 'known', 'ko', 'kumar', 'la', 'lac', 'laga', 'lahoreblast', 'lakh', 'lakhs', 'lang', 'larger', 'las', 'last', 'later', 'latest', 'latter', 'laws', 'le', 'leader', 'leave', 'ledwho', 'lemons', 'lengths', 'leroy', 'les', 'let', 'lets', 'lettera', 'liar', 'liberal', 'liberals', 'lie', 'lieing', 'lies', 'life', 'lifestyle', 'lifestylechange', 'like', 'likelihood', 'limit', 'line', 'liner', 'lines', 'list', 'lista', 'listed', 'listen', 'litre', 'live', 'liveaction', 'livehealthy', 'lives', 'living', 'lo', 'loans', 'logo', 'lok', 'loksabhaelections', 'lol', 'looks', 'lord', 'los', 'loss', 'lost', 'lot', 'loved', 'lowest', 'lying', 'm_lekhi', 'ma', 'maa', 'maarke', 'macros', 'made', 'maggio', 'mahatma', 'mail', 'majoritarian', 'majority', 'make', 'makes', 'making', 'malik', 'mamata', 'mamatadidijaishriram', 'mamataofficial', 'mamta', 'man', 'mandir', 'mangal', 'manifesto', 'manmohan', 'manogya', 'manogyaloiwal', 'manojtiwarimp', 'mantri', 'many', 'map', 'maptition', 'march', 'marg', 'market', 'married', 'mask', 'masoodazhar', 'mat', 'match', 'matter', 'matthewmodine', 'mau', 'maury', 'may', 'mayawati', 'me', 'mea', 'measly', 'media', 'medicacin', 'medicamentos', 'medicine', 'meeting', 'mehtas', 'men', 'mere', 'message', 'met', 'mi', 'middle', 'middleman', 'midst', 'miguel', 'milano', 'miles', 'minister', 'mirrornow', 'mischief', 'missed', 'mission', 'mistresses', 'misused', 'modi', 'modiaanewalahai', 'modibharosa', 'modifi', 'modifica', 'modificados', 'modifican', 'modification', 'modifiedvikas', 'modifier', 'modifies', 'modify', 'modihaitovikashai', 'modihiaayega', 'modiji', 'modikafakegdp', 'modilie', 'modilies', 'modimadedisaster', 'modioncemore', 'modis', 'mods', 'mohsinkhan', 'moment', 'momo_mohsin', 'money', 'more', 'moron', 'morphed', 'mort', 'most', 'mostly', 'mother', 'motive', 'mps', 'mr', 'mrcc', 'msme', 'much', 'mufasa', 'mughal', 'mujhe', 'mujhse', 'mum', 'muslim', 'must', 'my', 'naik', 'nailed', 'nambiji', 'name', 'namo', 'naqaab', 'naranja', 'narendra', 'narendramodi', 'nathuram', 'nation', 'national', 'nationalist', 'naturalgas', 'nature', 'naval', 'navaratri', 'nawab', 'nd', 'ndtv', 'nearly', 'need', 'negative', 'nehru', 'never', 'neverland', 'new', 'newly', 'ngel', 'nh', 'ni', 'nights', 'nirahua', 'nmero', 'no', 'nobody', 'non', 'nostra', 'not', 'nothing', 'nouvelle', 'now', 'nsitharaman', 'nude', 'number', 'nutrition', 'nyayvsanyay', 'obsessive', 'of', 'officer', 'official', 'omarabdullah', 'on', 'once', 'one', 'one_by_two', 'only', 'openly', 'opportunity', 'opulent', 'or', 'original', 'originalanmol', 'orina', 'other', 'ou', 'our', 'oust', 'outlook', 'outsmart', 'over', 'own', 'pacientes', 'pack', 'paid', 'pakistan', 'pandey', 'par', 'parameters', 'parischa', 'pariwar', 'part', 'partied', 'parties', 'party', 'pasado', 'pasan', 'pasricha', 'past', 'pata', 'patriot', 'patriotism', 'patriots', 'pawankhera', 'pay', 'paying', 'pelotudos', 'people', 'per', 'perfidy', 'period', 'person', 'personal', 'personalities', 'personally', 'pessimism', 'petit', 'petrol', 'phase', 'phenomenon', 'phirekbaarmodisarkar', 'phoney', 'pic', 'picture', 'piece', 'pierdan', 'pirpanjal', 'piyushgoyaloffc', 'planned', 'please', 'plz', 'pm', 'pmay', 'pmoindia', 'policies', 'political', 'polls', 'polygraph', 'pooja', 'poor', 'porque', 'portioncontrol', 'position', 'positive', 'posts', 'pour', 'poverty', 'power', 'pradesh', 'pradhan', 'pragya', 'pragyathakur', 'pratap', 'praveen', 'pray', 'prays', 'pre', 'pregnancies', 'premi', 'president', 'press', 'price', 'prime', 'primeminister', 'prince', 'priority', 'priyankagandhi', 'pro', 'prof_hariom', 'programmes', 'progressive', 'proliferate', 'promising', 'property', 'protection', 'protocolo', 'proud', 'ptition', 'ptitions', 'pubblica', 'public', 'pueden', 'puisque', 'puja', 'puri', 'purulia', 'put', 'putting', 'pvnr', 'quale', 'que', 'queen__hancock', 'quelques', 'question', 'questions', 'qui', 'quran', 'rabindrajayanti', 'rabindranath', 'rabridevirjd', 'radio', 'rahul', 'rahulgandhi', 'rahulkachallenge', 'rahulkanwal', 'raised', 'raj', 'rajdeep', 'rajeev', 'rajiv', 'rajivgandhi', 'rajnathsingh', 'rajputana', 'rally', 'ram', 'ramesh_bjp', 'ramsabjym', 'ramzan', 'ranked', 'rather', 'ravikishann', 'ravish', 'rbi', 'rd', 're', 'reach', 'read', 'real', 'reality', 'really', 'reallyswara', 'record', 'records', 'reduction', 'registered', 'regressive', 'reign', 'reject', 'rejected', 'relatore', 'reliance', 'remark', 'remarks', 'reminder', 'renukasingh', 'replace', 'reply', 'report', 'reporter', 'reports', 'resources', 'responses', 'resto', 'retd', 'return', 'returns', 'rickshaw', 'rien', 'right', 'rise', 'risposta', 'roadshow', 'roasting', 'robert', 'roja', 'rok', 'roots', 'rosa', 'roshankrrai', 'royal', 'royalty', 'rs', 'rsprasad', 'rss', 'rssurjewala', 'rt', 'rule', 'ruling', 'run', 'running', 'rural', 'saagar_anand', 'sabha', 'sabsebadajhootamodi', 'sad', 'sadhvi', 'safe', 'sagaftra', 'said', 'saison', 'sako', 'samajwadi', 'sambitswaraj', 'same', 'sandeepfromvns', 'sangh', 'sanjaynirupam', 'saraxstan_kiddo', 'sardesai', 'sarkar', 'sath', 'savarkar', 'savebengalsavedemocracy', 'say', 'saying', 'says', 'scam', 'scams', 'scamsters', 'schools', 'screenshot', 'scroll_in', 'se', 'sealing', 'secretary', 'sector', 'secular', 'securities', 'see', 'seen', 'selfish', 'sell', 'sena', 'sengarajay', 'sengardeep', 'senior', 'sent', 'senza', 'serious', 'services', 'sest', 'set', 'shah', 'shame', 'shameful', 'share', 'shatrughan', 'she', 'shiv', 'should', 'show', 'shown', 'shows', 'shree', 'shri', 'si', 'sick', 'siddaramaiah', 'side', 'sighed', 'sign', 'silent', 'sin', 'singh', 'sinha', 'sir', 'sirius', 'skfc', 'sky', 'slap', 'slapped', 'sledgehammer_ff', 'sleeping', 'sleepless', 'slip', 'smart', 'smritiirani', 'snikhil_social', 'so', 'social', 'sociales', 'socialtamasha', 'society', 'sofferenze', 'soit', 'some', 'someone', 'something', 'someway', 'somos', 'source', 'sp', 'speaks', 'speech', 'spence', 'spending', 'spewing', 'spotted', 'srivatsayb', 'star', 'started', 'state', 'statement', 'statements', 'statue', 'statues', 'stays', 'still', 'stock', 'stocks', 'stone', 'stop', 'story', 'strada', 'straight', 'strategic', 'strategy', 'stretch', 'strikes', 'student', 'stupid', 'stupidly', 'su', 'suban', 'success', 'successfull', 'such', 'suddenly', 'sudhirchaudhary', 'suggested', 'suitable', 'sultan', 'sunil_deodhar', 'sunnies', 'super', 'suppor', 'support', 'supporting', 'supports', 'sur', 'sure', 'suresh', 'sureshchavhanke', 'sureshnakhua', 'sureshpprabhu', 'surgical', 'surrogacy', 'sushmahabala', 'sushmaswaraj', 'swamigeetika', 'swamy', 'tagore', 'tajinderbagga', 'take', 'taken', 'taking', 'tal', 'talented', 'talk', 'taught', 'tax', 'taxi', 'taxpayer', 'teachers', 'telefnico', 'tell', 'telling', 'tells', 'tengan', 'tera', 'tere', 'term', 'terrorist', 'test', 'th', 'thakur', 'than', 'thankfully', 'thanks', 'that', 'the', 'the_abhi', 'theamitbhati', 'thecountdown', 'their', 'them', 'then', 'theprintindia', 'these', 'theskindoctor', 'theweeklive', 'thewire_in', 'they', 'thieves', 'things', 'this', 'thomas', 'those', 'threat', 'threw', 'time', 'times', 'tired', 'tmc', 'to', 'today', 'todo', 'toh', 'tolabaji', 'too', 'top', 'topic', 'touch', 'tout', 'trabajo', 'tracker', 'tradebulls', 'traitor', 'transform', 'transformation', 'transforming', 'transporte', 'trasplante', 'travels', 'trazione', 'treachery', 'tremendously', 'trending', 'tres', 'trial', 'tried', 'trinamool', 'trips', 'trne', 'troll_modi', 'trolleys', 'trouble', 'trouve', 'trucks', 'true', 'trump', 'trust', 'try', 'ttt', 'tue', 'tujhe', 'tukde', 'tuning', 'turned', 'tweet', 'tweeted', 'twitter', 'uber', 'uidai', 'uidaidelhi', 'un', 'unabated', 'unable', 'uncomfortable', 'under', 'understand', 'une', 'unemployment', 'unfit', 'union', 'unnatural', 'unturned', 'up', 'upa', 'upadhyay', 'urmila', 'usando', 'use', 'used', 'usher', 'using', 'utar', 'uttar', 'va', 'vacancies', 'vacant', 'vacation', 'vacationed', 'vajpayee', 'valiant', 'vanitajain', 'varshneys', 'vasundharabjp', 'veganlifestyle', 'venom', 'version', 'very', 'vi', 'via', 'vice', 'vices', 'victim', 'video', 'vidyasagars', 'vijaysankalprally', 'vikas', 'vile', 'village', 'villes', 'vinatanycost', 'vinod', 'vinodchavdabjp', 'violence', 'violent', 'viraat', 'viral', 'virat', 'vision', 'viviendo', 'voir', 'voldemort', 'volunteers', 'vote', 'votebjp', 'voted', 'votemodi', 'votenyayvotecongress', 'voting', 'votinground', 'vp', 'vs', 'waiting', 'was', 'watch', 'watched', 'water', 'way', 'we', 'wearing', 'wednesdaywisdom', 'week', 'weightloss', 'well', 'were', 'west', 'what', 'when', 'where', 'which', 'while', 'who', 'whopping', 'whose', 'why', 'widely', 'wikisubs', 'will', 'win', 'wins', 'wire', 'wisely', 'wish', 'with', 'withdraw', 'without', 'witnessed', 'women', 'won', 'word', 'work', 'working', 'worried', 'worry', 'worshipped', 'would', 'writes', 'wsj', 'yadav', 'yadavdimples', 'ye', 'year', 'years', 'yes', 'yojana', 'yoongi', 'you', 'your', 'youve', 'yrkkh', 'yrs', 'zakir', 'zeenews', 'zeenewshindi']\n"
     ]
    }
   ],
   "source": [
    "print (vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1607\n"
     ]
    }
   ],
   "source": [
    "print (len(vect.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(185, 1607)\n"
     ]
    }
   ],
   "source": [
    "# transform the documents in the training data to a document-term matrix\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "X_train_vectorized\n",
    "\n",
    "print ((X_train_vectorized.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train the model\n",
    "model = LogisticRegression(solver='lbfgs', multi_class='auto')\n",
    "model.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.6134291699961071\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "    return roc_auc_score(y_test, y_pred, average=average)\n",
    "\n",
    "# Predict the transformed test documents\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "\n",
    "print('AUC: ', multiclass_roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs:\n",
      "['tmc' 'zeenews' 'today' 'incindia' '__' 'says' 'narendra'\n",
      " 'phirekbaarmodisarkar' 'interview' 'dev_fadnavis']\n",
      "\n",
      "Largest Coefs: \n",
      "['pm' 'godse' 'apnamodiaayega' 'deshkagauravmodi' 'deshkedilmeimodi'\n",
      " 'aayegatomodihi' 'modiaanewalahai' 'bjpindia' 'rahulkachallenge'\n",
      " 'justiceforvishnugoswami']\n"
     ]
    }
   ],
   "source": [
    "# get the feature names as numpy array\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "# Sort the coefficients from the model\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "# Find the 10 smallest and 10 largest coefficients\n",
    "# The 10 largest coefficients are being indexed using [:-11:-1] \n",
    "# so the list returned is in order of largest to smallest\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# These reviews are treated the same by our current model\n",
    "print(model.predict(vect.transform(['apna modi aaega'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# These reviews are treated the same by our current model\n",
    "print(model.predict(vect.transform([' narendramodi sureshpprabhu harvotemodiko '])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n"
     ]
    }
   ],
   "source": [
    "# These reviews are treated the same by our current model\n",
    "print(model.predict(vect.transform([' bjpindia narendramodi incindia pawankhera sambitswaraj this is real modi '])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Fit the TfidfVectorizer to the training data specifiying a minimum document frequency of 5\n",
    "vect = TfidfVectorizer(min_df=5).fit(X_train)\n",
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.5387365029606409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "    return roc_auc_score(y_test, y_pred, average=average)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "\n",
    "print('AUC: ', multiclass_roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest tfidf:\n",
      "['when' 'an' 'vinod' 'we' 'sabsebadajhootamodi' 'because' 'it' 'bjp' 'all'\n",
      " 'minister']\n",
      "\n",
      "Largest tfidf: \n",
      "['me' 'deshkishaanmodi' 'la' 'tajinderbagga' 'apnamodiaayega'\n",
      " 'narendramodi' 'bjpindia' 'mamataofficial' 'my' 'narendra']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "sorted_tfidf_index = X_train_vectorized.max(0).toarray()[0].argsort()\n",
    "\n",
    "print('Smallest tfidf:\\n{}\\n'.format(feature_names[sorted_tfidf_index[:10]]))\n",
    "print('Largest tfidf: \\n{}'.format(feature_names[sorted_tfidf_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs:\n",
      "['la' 'narendra' 'says' 'today' 'why' 'and' 'watch' 'as' 'we' 'who']\n",
      "\n",
      "Largest Coefs: \n",
      "['apnamodiaayega' 'india' 'godse' 'pm' 'bjpindia' 'time' 'upa' 'my' 'will'\n",
      " 'to']\n"
     ]
    }
   ],
   "source": [
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# These reviews are treated the same by our current model\n",
    "print(model.predict(vect.transform(['apna modi aaega'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "# These reviews are treated the same by our current model\n",
    "print(model.predict(vect.transform([ 'sanjaynirupam sir modi ki puri baja di hai apne why the newly appointed mrcc president doesn talk why he stays mum all the time' ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the CountVectorizer to the training data specifiying a minimum \n",
    "# document frequency of 5 and extracting 1-grams and 2-grams\n",
    "vect = CountVectorizer(min_df=5, ngram_range=(1,2)).fit(X_train)\n",
    "\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.5917965148441822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "    return roc_auc_score(y_test, y_pred, average=average)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "\n",
    "print('AUC: ', multiclass_roc_auc_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs:\n",
      "['says' 'why' 'we' 'narendra' 'la' 'today' 'watch' 'an' 'about' 'many']\n",
      "\n",
      "Largest Coefs: \n",
      "['apnamodiaayega' 'time' 'godse' 'india' 'upa' 'be' 'not' 'pm'\n",
      " 'mamataofficial' 'will']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.6031604073186223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Fit the CountVectorizer to the training data specifiying a minimum \n",
    "# document frequency of 5 and extracting 1-grams and 2-grams\n",
    "vect = CountVectorizer(min_df=5, ngram_range=(1,2)).fit(X_train)\n",
    "\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "len(vect.get_feature_names())\n",
    "\n",
    "\n",
    "\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "X_train_vectorized.todense()\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "    return roc_auc_score(y_test, y_pred, average=average)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "\n",
    "print('AUC: ', multiclass_roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.591201057225398\n"
     ]
    }
   ],
   "source": [
    "#vect = TfidfVectorizer(min_df=5).fit(X_train)\n",
    "vect = CountVectorizer(min_df=5, ngram_range=(1,2)).fit(X_train)\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "\n",
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "    return roc_auc_score(y_test, y_pred, average=average)\n",
    "\n",
    "model = LDA()\n",
    "model.fit(X_train_vectorized.toarray(), y_train)\n",
    "\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "\n",
    "print('AUC: ', multiclass_roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(vect.transform(['i am a bad boi'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(vect.transform(['there has been fire in amazon'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(vect.transform([' narendramodi sureshpprabhu harvotemodiko '])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(vect.transform([' bjpindia narendramodi incindia pawankhera sambitswaraj this is real modi '])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# Fit the TfidfVectorizer to the training data specifiying a minimum document frequency of 5\n",
    "#vect = TfidfVectorizer(min_df=5).fit_transform(X_train)\n",
    "#len(vect.get_feature_names())\n",
    "\n",
    "no_features = 1000\n",
    "\n",
    "# NMF is able to use tf-idf\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "no_topics = 20\n",
    "\n",
    "# Run NMF\n",
    "nmf = NMF(n_components=no_topics, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(vect)\n",
    "\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(X_train)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "\n",
    "\n",
    "# Run LDA\n",
    "lda = LatentDirichletAllocation(no_topics, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(tf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "did amitshahoffice end bjp elections grew followed country came credit\n",
      "Topic 1:\n",
      "father disgusting followed claim bjpindia asks fans didn gandhis grew\n",
      "Topic 2:\n",
      "banerjee different called grew hai chouhanshivraj bjp bjpindia brother business\n",
      "Topic 3:\n",
      "admiral elections fridayfeeling family different called hai candidate bjp bjpindia\n",
      "Topic 4:\n",
      "candidate brother deshkedilmeimodi follow fy allowed growth good dev_fadnavis dear\n",
      "Topic 5:\n",
      "armed family claim followed credit deshkedilmeimodi bjp didn amit bjpindia\n",
      "Topic 6:\n",
      "does asks elections drive hai claim good gandhis grew gandhi\n",
      "Topic 7:\n",
      "common hai claim bjp bjpindia brother business called came candidate\n",
      "Topic 8:\n",
      "deshkedilmeimodi chouhanshivraj elections best bjpindia es fridayfeeling claim amit disgusting\n",
      "Topic 9:\n",
      "freedom fans address business feel ask deshkedilmeimodi grew follow __\n",
      "Topic 10:\n",
      "addressing class best attacked business deshkedilmeimodi candidate called aayega corruption\n",
      "Topic 11:\n",
      "great disgusting en dont amitshahoffice amp apnamodiaayega chouhanshivraj got candidate\n",
      "Topic 12:\n",
      "crore family deshkedilmeimodi hai chouhanshivraj bjp bjpindia brother business called\n",
      "Topic 13:\n",
      "habitual hai disgusting going didn best amit govt forces candidate\n",
      "Topic 14:\n",
      "country amitshah claim elections candidate apnamodiaayega es fridayfeeling great didn\n",
      "Topic 15:\n",
      "aayegatomodihi came apnamodiaayega credit didn hai claim bjpindia brother business\n",
      "Topic 16:\n",
      "deshkishaanmodi ask amitshah best deshkagauravmodi different bjp grew benefited crore\n",
      "Topic 17:\n",
      "bengal friends deshkedilmeimodi come govt candidate disgusting better amit growth\n",
      "Topic 18:\n",
      "delhi deshkedilmeimodi claim habitual corruption good freedom hai candidate bjp\n",
      "Topic 19:\n",
      "abkibaarpaar godse bjp deshkedilmeimodi called claim address came corruption free\n",
      "Topic 0:\n",
      "amitshah phirekbaarmodisarkar th amitshahoffice tajinderbagga deshkishaanmodi really apnamodiaayega success bjpindia\n",
      "Topic 1:\n",
      "en los la el se brother que es uber sir\n",
      "Topic 2:\n",
      "narendramodi rally attacked silent answer amitshah people vinod set shri\n",
      "Topic 3:\n",
      "mamataofficial price ram __ people hi ask lives answer different\n",
      "Topic 4:\n",
      "win people like lot free period version business talk women\n",
      "Topic 5:\n",
      "narendramodi modi apnamodiaayega sure dev_fadnavis rsprasad crore indians right don\n",
      "Topic 6:\n",
      "aayegatomodihi family silent hand pm like misused modi hasn ins\n",
      "Topic 7:\n",
      "narendramodi amp godse gandhi bjpindia bjp pragya killed disgusting father\n",
      "Topic 8:\n",
      "modihiaayega rajivgandhi vice pm india apnamodiaayega vinod tajinderbagga lies new\n",
      "Topic 9:\n",
      "narendramodi pm apnamodiaayega interview live watch zeenews meeting hai addressing\n",
      "Topic 10:\n",
      "lies vinod set straight liar habitual vice sabsebadajhootamodi admiral nature\n",
      "Topic 11:\n",
      "bjpindia narendramodi modioncemore amitshah dont dev_fadnavis chouhanshivraj really sir feel\n",
      "Topic 12:\n",
      "government congress lying thanks job years jharkhandbolemodimodi modi deshkishaanmodi narendra\n",
      "Topic 13:\n",
      "modi pm amp fy india credit bjp narendra mamata years\n",
      "Topic 14:\n",
      "india power won bjp ji congress govt voting says narendramodi\n",
      "Topic 15:\n",
      "deshkagauravmodi uber modi rd modiaanewalahai won shame upa different apnamodiaayega\n",
      "Topic 16:\n",
      "deshkishaanmodi person jharkhandbolemodimodi life common right sure grew going benefited\n",
      "Topic 17:\n",
      "modi pm common godse fans nathuram twitter followed deshkedilmeimodi used\n",
      "Topic 18:\n",
      "une la se pm bjp modihiaayega jai tmc rally state\n",
      "Topic 19:\n",
      "narendramodi apnamodiaayega pm deshkagauravmodi amitshah sushmaswaraj rsprasad mamatadidijaishriram follow smritiirani\n"
     ]
    }
   ],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print (\"Topic %d:\" % (topic_idx))\n",
    "        print (\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "\n",
    "no_top_words = 10\n",
    "display_topics(nmf, tfidf_feature_names, no_top_words)\n",
    "display_topics(lda, tf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
